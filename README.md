
# ğŸŒ² AdaBoost ile Orman Ã–rtÃ¼sÃ¼ TÃ¼rÃ¼ SÄ±nÄ±flandÄ±rmasÄ±

Bu projede **ensemble learning** yÃ¶ntemlerinden biri olan **AdaBoost (Adaptive Boosting)** algoritmasÄ±nÄ± kullanarak, `covtype.csv` veri seti Ã¼zerinden orman Ã¶rtÃ¼sÃ¼ tÃ¼rlerini sÄ±nÄ±flandÄ±rdÄ±k.

---

## ğŸ“Œ 1. Ensemble Learning Nedir?

Ensemble Learning, birden fazla zayÄ±f modelin (Ã¶rneÄŸin tek baÅŸÄ±na pek baÅŸarÄ±lÄ± olmayan aÄŸaÃ§larÄ±n) bir araya gelerek gÃ¼Ã§lÃ¼ bir tahmin modeli oluÅŸturmasÄ±nÄ± saÄŸlar. Bu teknik Ã¼Ã§ ana gruba ayrÄ±lÄ±r:

- **Bagging** â†’ Ã–rnek: Random Forest ğŸŒ²
- **Boosting** â†’ Ã–rnek: AdaBoost âš¡
- **Stacking** â†’ FarklÄ± modellerin Ã§Ä±ktÄ±larÄ± birleÅŸtirilerek son model eÄŸitilir.

Bu projede odaklandÄ±ÄŸÄ±mÄ±z yÃ¶ntem **Boosting**, Ã¶zellikle de **AdaBoost** algoritmasÄ±dÄ±r.

---

## âš¡ 2. AdaBoost Nedir?

**AdaBoost (Adaptive Boosting)**, karar aÄŸaÃ§larÄ± gibi zayÄ±f sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ± art arda eÄŸitip birleÅŸtirerek gÃ¼Ã§lÃ¼ bir model Ã¼retir.

ğŸ” Her adÄ±mda model hatalÄ± sÄ±nÄ±flandÄ±rdÄ±ÄŸÄ± Ã¶rneklere daha fazla aÄŸÄ±rlÄ±k verir.  
ğŸ¯ AmaÃ§: ZayÄ±f Ã¶ÄŸrenicileri zincirleme kullanarak hatalarÄ± azaltmak.  
ğŸŒ³ Genellikle temel Ã¶ÄŸrenici olarak **DecisionTreeClassifier (max_depth=1)** kullanÄ±lÄ±r.

---

## â“ Neden AdaBoost KullandÄ±k?

- Orman Ã¶rtÃ¼sÃ¼ gibi **karmaÅŸÄ±k ve Ã§ok boyutlu** verilerde, doÄŸrusal olmayan iliÅŸkileri Ã¶ÄŸrenmekte Ã§ok baÅŸarÄ±lÄ±.
- Tek baÅŸÄ±na karar aÄŸacÄ± modellerinden **daha yÃ¼ksek doÄŸruluk saÄŸlar**.
- Boosting'in doÄŸasÄ± gereÄŸi **aÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ Ã¶ÄŸrenme** sayesinde, zor Ã¶rneklerde daha isabetli tahminler yapÄ±labilir.

---

## ğŸ“Š 3. KullanÄ±lan Veri Seti: `covtype.csv`

- Veri KÃ¼mesi: 581.012 satÄ±r, 55 sÃ¼tun
- AmaÃ§: Son sÃ¼tun olan `Cover_Type`'Ä± tahmin etmek
- Ã–zellikler:
  - SayÄ±sal veriler: `Elevation`, `Slope`, `Hillshade`, `Distance` sÃ¼tunlarÄ±
  - One-hot encoded veriler: `Wilderness_Area` (4 kolon), `Soil_Type` (40 kolon)

ğŸ“ Veri kÃ¼mesi Kaggleâ€™dan alÄ±nmÄ±ÅŸtÄ±r ve yaygÄ±n olarak sÄ±nÄ±flandÄ±rma problemlerinde kullanÄ±lÄ±r.

---

## ğŸ”§ 4. KullanÄ±lan KÃ¼tÃ¼phaneler ve Sebepleri

- `pandas`: Veri yÃ¼kleme ve iÅŸleme iÃ§in
- `numpy`: SayÄ±sal iÅŸlemler iÃ§in
- `sklearn.model_selection.train_test_split`: EÄŸitim/test bÃ¶lme
- `sklearn.preprocessing.StandardScaler`: Ã–lÃ§ekleme
- `sklearn.ensemble.AdaBoostClassifier`: Ana model
- `sklearn.tree.DecisionTreeClassifier`: Temel sÄ±nÄ±flandÄ±rÄ±cÄ±
- `sklearn.metrics`: Accuracy, classification_report, confusion matrix gibi metrikler

---

## ğŸ” 5. Model YapÄ±sÄ±

```python
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier

base_estimator = DecisionTreeClassifier(max_depth=1)
model = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, learning_rate=1.0)
```

### AÃ§Ä±klama:
- `base_estimator`: Her bir adÄ±mda kullanÄ±lan karar aÄŸacÄ± modeli. `max_depth=1` seÃ§ildi Ã§Ã¼nkÃ¼ boosting algoritmalarÄ± zayÄ±f Ã¶ÄŸreniciler ile Ã§alÄ±ÅŸÄ±r.
- `n_estimators`: Toplam kaÃ§ zayÄ±f model oluÅŸturulacak?
- `learning_rate`: Her zayÄ±f modelin etkisini belirler.

---

## ğŸ“ˆ 6. Model PerformansÄ±

| Metrik                 | DeÄŸer |
|------------------------|-------|
| DoÄŸruluk (Accuracy)    | %83   |
| Precision, Recall, F1  | SÄ±nÄ±flara gÃ¶re detaylÄ± raporlandÄ±
| Confusion Matrix       | ğŸ”² ğŸ”³ ğŸ”² ğŸ”³ (yÃ¼ksek baÅŸarÄ±, bazÄ± sÄ±nÄ±flarda karÄ±ÅŸÄ±klÄ±k)

ğŸ“Œ Not: AdaBoost modeli Ã¶zellikle belirli sÄ±nÄ±flarda (Ã¶rneÄŸin 1 ve 2. tÃ¼rlerde) Ã§ok baÅŸarÄ±lÄ± tahminler yaptÄ±. Ancak bazÄ± benzer sÄ±nÄ±flar arasÄ±nda (Ã¶rneÄŸin 4 ve 5) karÄ±ÅŸmalar gÃ¶zlemlendi.

---

## âœ… AdaBoostâ€™un AvantajlarÄ±

- HatalÄ± sÄ±nÄ±flandÄ±rmalardan Ã¶ÄŸrenir ğŸ”
- AÄŸÄ±rlÄ±klandÄ±rma ile zor Ã¶rneklerde geliÅŸme saÄŸlar
- DiÄŸer yÃ¶ntemlere kÄ±yasla Ã§ok bÃ¼yÃ¼k veri setlerinde bile hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r

---

## âš ï¸ Dikkat Edilmesi Gerekenler

- Outlier'lara karÅŸÄ± duyarlÄ±dÄ±r ğŸš¨
- Overfitting riski yok denemez, ama genelde dÃ¼ÅŸÃ¼ktÃ¼r
- Her zaman daha iyi demek deÄŸil, veri setine gÃ¶re model seÃ§ilmelidir

---

## ğŸ“ Projeyi Ã‡alÄ±ÅŸtÄ±rmak Ä°Ã§in

1. Python 3.8+ yÃ¼klÃ¼ olmalÄ±
2. Gerekli kÃ¼tÃ¼phaneleri yÃ¼kle:
```bash
pip install -r requirements.txt
```
3. Notebook'u Ã§alÄ±ÅŸtÄ±r: `adaboost.ipynb`
4. SonuÃ§larÄ± gÃ¶zlemle ğŸ“Š

---

## ğŸ§  Bonus: AdaBoost vs. DiÄŸer YÃ¶ntemler

| Ã–zellik        | AdaBoost     | Random Forest |
|----------------|--------------|----------------|
| Model tÃ¼rÃ¼     | Boosting     | Bagging        |
| Ã–ÄŸrenme tipi   | AÄŸÄ±rlÄ±klÄ±    | Rastgele Ã¶rnekleme |
| Hedef          | HatalÄ± Ã¶rneklerden ders alma | Overfittingâ€™i azaltma |
| Base Learner   | ZayÄ±f (depth=1) karar aÄŸacÄ± | Karar aÄŸaÃ§larÄ± |

---

## âœï¸ KatkÄ± ve Lisans

Bu proje eÄŸitim amaÃ§lÄ±dÄ±r. Her tÃ¼rlÃ¼ Ã¶neri, katkÄ± ve yÄ±ldÄ±z â­ memnuniyetle karÅŸÄ±lanÄ±r.
